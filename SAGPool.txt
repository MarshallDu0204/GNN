SAGPool

数据预处理：
normalization
L=D^-0.5 * (A+I) * D^-0.5
作用: 增加节点本身的影响以及normalization

1）
graph pooling

方法：注意力机制
链接：https://arxiv.org/pdf/1904.08082.pdf
引入注意力机制从而对图的关键点进行保留实现池化(生成对图的mask)
运算逻辑：
Graph 经过三次GCN运算后 有邻接矩阵以及节点特征
graph pooling层 邻接矩阵，节点特征作为输入，输出一个(node_num,1) 1维的节点特征向量作为attention-mask
利用attention-mask图的节点进行打分，对原图进行pooling操作，每次保留top-k个节点

2)
readout 层
对输出的图的特征矩阵进行aggregate从而实现固定大小输出，通过全局池化将各个图降维到同一维度
方法分别为global max pool 和 global average pool 对图中所有节点进行global pooling(融合全部节点的结果)压缩为统一维度,
并将两种输出的结果拼接
从而实现对任意一个图输出一个固定大小的矩阵

在提供的D&D数据集中总共有1178张图，总共334925个node, 作者提供了一张334925*334925的ajency matrix，
并提供了一个(334925,)的graph indicator，形式为[0 0 0 ....1177 1177 1177] 从而可以借助graph indicator 实现从
总的ajency matrix 中提取出单个的图 并依照graph indicator对单个图的所有节点进行global pooling 压缩单图中所有节点信息

输出矩阵进而可以通过mlp+softmax进行分类

可以通过graph pooling 与 readout 实现对整张图的分类

Graph--> GCN --> pooling --> GCN --> pooling --> Readout --> mlp --> softmax